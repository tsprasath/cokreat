apiVersion: v1
kind: Conf
metadata:
  name: {{ .Chart.Name }}-service
  namespace: {{ .Release.namespace }}
data:
  search-service_application.conf: |
    default-dispatcher {
        fork-join-executor {
        parallelism-min = 8
        parallelism-factor = 32.0
        parallelism-max = 64
        task-peeking-mode = "FIFO"
        }
    }
    actors-dispatcher {
        type = "Dispatcher"
        executor = "fork-join-executor"
        fork-join-executor {
        parallelism-min = 8
        parallelism-factor = 32.0
        parallelism-max = 64
        }
        # Throughput for default Dispatcher, set to 1 for as fair as possible
        throughput = 1
    }
    actor {
        deployment {
        /searchActor
            {
            router = smallest-mailbox-pool
            nr-of-instances = 10
            dispatcher = actors-dispatcher
            }
        /healthActor
            {
            router = smallest-mailbox-pool
            nr-of-instances = 10
            dispatcher = actors-dispatcher
            }
        }
    }
    }

    play.http.secret.key = a-long-secret-to-calm-the-rage-of-the-entropy-gods

    play.modules {
    enabled += modules.SearchModule
    }
    play.i18n {
    langs = [ "en" ]
    }
    play.http {

    session {
        # Sets the cookie to be sent only over HTTPS.
        #secure = true

        # Sets the cookie to be accessed only by the server.
        #httpOnly = true

        # Sets the max-age field of the cookie to 5 minutes.
        # NOTE: this only sets when the browser will discard the cookie. Play will consider any
        # cookie value with a valid signature to be a valid session forever. To implement a server side session timeout,
        # you need to put a timestamp in the session and check it at regular intervals to possibly expire it.
        #maxAge = 300

        # Sets the domain on the session cookie.
        #domain = "example.com"
    }

    flash {
        # Sets the cookie to be sent only over HTTPS.
        #secure = true

        # Sets the cookie to be accessed only by the server.
        #httpOnly = true
    }
    }

    play.http.parser.maxDiskBuffer = 10MB
    parsers.anyContent.maxLength = 10MB

    play.server.provider = play.core.server.NettyServerProvider
    play.server.netty {
    log.wire = true

    transport = "native"
    }

    play.ws {
    # Sets HTTP requests not to follow 302 requests
    #followRedirects = false

    # Sets the maximum number of open HTTP connections for the client.
    #ahc.maxConnectionsTotal = 50

    ## WS SSL
    # https://www.playframework.com/documentation/latest/WsSSL
    # ~~~~~
    ssl {
        # Configuring HTTPS with Play WS does not require programming.  You can
        # set up both trustManager and keyManager for mutual authentication, and
        # turn on JSSE debugging in development with a reload.
        #debug.handshake = true
        #trustManager = {
        #  stores = [
        #    { type = "JKS", path = "exampletrust.jks" }
        #  ]
        #}
    }
    }

    ## Cache
    # https://www.playframework.com/documentation/latest/JavaCache
    # https://www.playframework.com/documentation/latest/ScalaCache
    # ~~~~~
    # Play comes with an integrated cache API that can reduce the operational
    # overhead of repeated requests. You must enable this by adding to build.sbt:
    #
    # libraryDependencies += cache
    #
    play.cache {
    # If you want to bind several caches, you can bind the individually
    #bindCaches = ["db-cache", "user-cache", "session-cache"]
    }

    ## Filter Configuration
    # https://www.playframework.com/documentation/latest/Filters
    # ~~~~~
    # There are a number of built-in filters that can be enabled and configured
    # to give Play greater security.
    #
    play.filters {

    # Enabled filters are run automatically against Play.
    # CSRFFilter, AllowedHostFilters, and SecurityHeadersFilters are enabled by default.
    enabled = [filters.AccessLogFilter]

    # Disabled filters remove elements from the enabled list.
    # disabled += filters.CSRFFilter


    ## CORS filter configuration
    # https://www.playframework.com/documentation/latest/CorsFilter
    # ~~~~~
    # CORS is a protocol that allows web applications to make requests from the browser
    # across different domains.
    # NOTE: You MUST apply the CORS configuration before the CSRF filter, as CSRF has
    # dependencies on CORS settings.
    cors {
        # Filter paths by a whitelist of path prefixes
        #pathPrefixes = ["/some/path", ...]

        # The allowed origins. If null, all origins are allowed.
        #allowedOrigins = ["http://www.example.com"]

        # The allowed HTTP methods. If null, all methods are allowed
        #allowedHttpMethods = ["GET", "POST"]
    }

    ## Security headers filter configuration
    # https://www.playframework.com/documentation/latest/SecurityHeaders
    # ~~~~~
    # Defines security headers that prevent XSS attacks.
    # If enabled, then all options are set to the below configuration by default:
    headers {
        # The X-Frame-Options header. If null, the header is not set.
        #frameOptions = "DENY"

        # The X-XSS-Protection header. If null, the header is not set.
        #xssProtection = "1; mode=block"

        # The X-Content-Type-Options header. If null, the header is not set.
        #contentTypeOptions = "nosniff"

        # The X-Permitted-Cross-Domain-Policies header. If null, the header is not set.
        #permittedCrossDomainPolicies = "master-only"

        # The Content-Security-Policy header. If null, the header is not set.
        #contentSecurityPolicy = "default-src 'self'"
    }

    ## Allowed hosts filter configuration
    # https://www.playframework.com/documentation/latest/AllowedHostsFilter
    # ~~~~~
    # Play provides a filter that lets you configure which hosts can access your application.
    # This is useful to prevent cache poisoning attacks.
    hosts {
        # Allow requests to example.com, its subdomains, and localhost:9000.
        #allowed = [".example.com", "localhost:9000"]
    }
    }

    play.http.parser.maxMemoryBuffer = 50MB
    akka.http.parsing.max-content-length = 50MB

    schema.base_path="https://stagingdock.blob.core.windows.net/content-service/schemas"


    telemetry_env="dock"
    installation.id="Sunbird_Staging"

    # ElasticSearch Configuration
    ekstepPlatformApiUserId="search-service"
    search.es_conn_info="11.4.1.7:9200"
    search.fields.query=["name^100","title^100","lemma^100","code^100","domain","subject","description^10","keywords^100","ageGroup^10","filter^10","theme^10","genre^10","objects^25","contentType^100","language^200","teachingMode^25","skills^10","learningObjective^10","curriculum^100","gradeLevel^100","developer^100","attributions^10","identifier^100","IL_UNIQUE_ID^100","owner^50","board^100","relatedBoards^100","creator^100", "dialcodes^100","text","words","releaseNotes"]
    search.fields.date=["lastUpdatedOn","createdOn","versionDate","lastSubmittedOn","lastPublishedOn"]
    search.fields.mode_collection=["identifier","name","objectType","contentType","mimeType","size","childNodes","board","subject","medium","gradeLevel","appIcon","resourceType","origin","originData"]
    search.batch.size=500
    search.connection.timeout=30

    language.map={"Hindi":"hi", "English":"en", "Telugu":"te", "Kannada":"ka", "Tamil":"ta", "Assamese":"as", "Bengali":"bn", "Bodo":"bo", "Gujarati":"gu", "Konkani":"ko", "Malayalam":"ml", "Marathi":"mr", "Nepali":"ne", "Odia":"or", "Punjabi":"pj", "Sanskrit":"san"}

    # Configuration for default channel ID
    channel.default="in.ekstep"
    compositesearch.index.name="compositesearch"

    content.tagging.backward_enable=false
    content.tagging.property=["subject","medium"]
    search.payload.log_enable=true
 
  search-service_logback.xml: |
    <configuration>

        <conversionRule conversionWord="coloredLevel" converterClass="play.api.libs.logback.ColoredLevel" />

        <!-- transaction-event-trigger START -->
        <timestamp key="timestamp" datePattern="yyyy-MM-dd"/>
        <!-- common transactions logs -->
        <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
            <encoder>
                <pattern>%d %msg%n</pattern>
            </encoder>
        </appender>

        <appender name="ASYNCSTDOUT" class="ch.qos.logback.classic.AsyncAppender">
            <appender-ref ref="STDOUT" />
        </appender>


        <logger name="play" level="INFO" />
        <logger name="DefaultPlatformLogger" level="INFO" />
        <!-- Telemetry Loggers-->

        <root level="INFO">
            <appender-ref ref="ASYNCSTDOUT" />
        </root>


        <appender name="kafka-appender" class="com.github.danielwegener.logback.kafka.KafkaAppender">
            <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
                <pattern>%msg</pattern>
            </encoder>

            <topic>staging.telemetry.raw</topic>
            <!-- ensure that every message sent by the executing host is partitioned to the same partition strategy -->
            <keyingStrategy class="com.github.danielwegener.logback.kafka.keying.NoKeyKeyingStrategy" />
            <!-- block the logging application thread if the kafka appender cannot keep up with sending the log messages -->
            <deliveryStrategy class="com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy" />
            
            <!-- each <producerConfig> translates to regular kafka-client config (format: key=value) -->
            <!-- producer configs are documented here: https://kafka.apache.org/documentation.html#newproducerconfigs -->
            <!-- bootstrap.servers is the only mandatory producerConfig -->
            <producerConfig>bootstrap.servers=11.4.1.8:9092</producerConfig>
            <!-- don't wait for a broker to ack the reception of a batch.  -->
            <producerConfig>acks=0</producerConfig>
            <!-- wait up to 1000ms and collect log messages before sending them as a batch -->
            <producerConfig>linger.ms=15000</producerConfig>
            <!-- even if the producer buffer runs full, do not block the application but start to drop messages -->
            <producerConfig>max.block.ms=0</producerConfig>
            <!-- define a client-id that you use to identify yourself against the kafka broker -->
            <producerConfig>client.id=${HOSTNAME}-${CONTEXT_NAME}-logback-relaxed</producerConfig>

            <!-- there is no fallback <appender-ref>. If this appender cannot deliver, it will drop its messages. -->

        </appender>

        <logger name="TelemetryEventLogger" level="INFO">
            <appender-ref ref="kafka-appender" />
        </logger>
